fred[ttr[1]]
fred[ttr[2]]
training[, grep('^IL$', names(training))]
training[, grep('^IL', names(training))]
preproc <- preProcess(log10(IL_Train + 1), method = "pca", pcaComp = 2)
## subset according to column names that start with "IL"
IL_Train <- training[, grep('^IL', names(training))]
## Preprocess using PCA
preproc <- preProcess(log10(IL_Train + 1), method = "pca", pcaComp = 2)
IL_Train
IL_Train[, NA]
IL_Train[$values[, NA]
IL_Train$values[, NA]
IL_Train$values[, "NA"]
IL_Train$values
IL_Train[1][, "NA"]
IL_Train[1]
IL_Tr2ain[]
IL_Train[2]
subset <-  IL_Train[!complete.cases(IL_Train), ]
subset
subset1 <-  IL_Train[complete.cases(IL_Train), ]
subset1
preproc <- preProcess(training[, IL_Train], method = "pca", thresh = 0.9)
IL_Train
## subset according to column names that start with "IL"
IL_Train <- grep('^IL', names(training))
## Preprocess using PCA
preproc <- preProcess(training[, IL_Train], method = "pca", thresh = 0.9)
preproc <- preProcess(training[, IL_Train], method = "pca", thresh = 0.9)
print(preproc)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training[, grep('^IL', names(training)), diagnosis]
training[, grep('^IL', names(training)), "diagnosis"]
training[, grep('^IL, names(training)), training$diagnosis]
]
IL_Train1 <- training[, grep('^IL', names(training)), training$diagnosis]
## Model 1 - Predictors as-is
modFit1 <- train(diagnosis ~ ., data = IL_Train1, method = "glm")
)
modFit1 <- train(diagnosis ~ ., data = IL_Train1, method = "glm")
IL_Train1 <- training[, grep('^IL', names(training)), training$diagnosis]
IL_Train1 <- training[, grep('^IL', names(training))]
IL_Train1
IL_Train1 <- training[, training$diagnosis]
IL_Train1
## Create Training and Testing Sets by subsetting those starting with IL and diagnosis
IdxCol_IL <- grep("^IL", names(training))
names_IL <- names(training[,IdxCol_IL])
newcols <- c(names_IL,"diagnosis")
new_training <- training[,newcols]
new_testing <- testing [,newcols]
## Model 1 - Predictors as-is
modFit1 <- train(diagnosis ~ ., data = new_training, method = "glm")
install.packages('e1071', dependencies=TRUE)
## Create Training and Testing Sets by subsetting those starting with IL and diagnosis
IdxCol_IL <- grep("^IL", names(training))
names_IL <- names(training[,IdxCol_IL])
newcols <- c(names_IL,"diagnosis")
new_training <- training[,newcols]
new_testing <- testing [,newcols]
## Model 1 - Predictors as-is
modFit1 <- train(diagnosis ~ ., data = new_training, method = "glm")
predicted <- predict(modFit1, new_testing)
print(predicted)
str(new_testing)
str(new_testing[, - diagnosis])
str(new_testing[, - "diagnosis"])
str(new_testing[- diagnosis])
new_testing[, c("diagnosis") <- list(NULL)]
new_testing[, c("diagnosis")] <- list(NULL)
str(new_testing[, c("diagnosis")] <- list(NULL))
new_testing[, -c("diagnosis")]
subset(new_testing, select=-c(diagnosis))
new_testing
str(subset(new_testing, select=-c(diagnosis)))
str(new_testing)
str(new_training)
str(new_testing)
IdxCol_IL <- grep("^IL", names(training))
names_IL <- names(training[,IdxCol_IL])
newcols <- c(names_IL,"diagnosis")
new_training <- training[,newcols]
new_testing <- testing [,newcols]
str(new_training)
str(new_testing)
modFit1 <- train(diagnosis ~ ., data = new_training, method = "glm")
predicted1 <- predict(modFit1, new_testing)
confusionMatrix(predicted1, new_testing$diagnosis)
train_PCA <- preProcess(new_training, method = "pca", thresh = 0.8)
train_PCA <- preProcess(new_testing, method = "pca", thresh = 0.8)
modelFit2 <- train(diagnosis ~ ., data = train_PCA, method="glm")
train_PCA <- preProcess(new_training, method = "pca", thresh = 0.8)
test_PCA <- preProcess(new_testing, method = "pca", thresh = 0.8)
modelFit2 <- train(diagnosis ~ ., data = train_PCA, method="glm")
train_PCA <- preProcess(new_training, method = "pca", thresh = 0.8)
str(train_PCA)
preProcessed_PCA <- preProcess(new_training, method = "pca", thresh = 0.8)
train_PCA <- predict(preProcessed_PCA, new_training)
modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
modelFit2 <- train(x = train_PCA, y = new_training$diagnosis, method="glm")
modelFit2 <- train(new_training$diagnosis ~ ., method="glm", data = train_PCA)
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[-13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[-13])
# Create the model from the created training set
modelFit2 <- train(new_training$diagnosis ~ ., method="glm", data = train_PCA)
## Model 2 - PCA, 80%, method = 'glm'
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[-13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[-13])
# Create the model from the created training set
modelFit2 <- train(new_training$training.diagnosis ~ ., method="glm", data = train_PCA)
new_training
str(new_training)
str(new_training[-13])
str(new_training[, -13])
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[, -13])
# Create the model from the created training set
modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[, -13])
# Create the model from the created training set
modelFit2 <- train(training$diagnosis ~ ., data = train_PCA, method="glm")
####################################################################################
## Model 2 - PCA, 80%, method = 'glm'
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[, -13])
# Create the model from the created training set
modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
# Create the model from the created training set
modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
## Model 2 - PCA, 80%, method = 'glm'
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[, -13])
# Create the model from the created training set
modelFit2 <- train(new_training$diagnosis ~ new_training [, -13], data = train_PCA, method="glm")
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[, -13])
# Create the model from the created training set
modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
## Model 2 - PCA, 80%, method = 'glm'
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[, -13])
# Create the model from the created training set
modelFit2 <- train(diagnosis ~ ., data = train_PCA, method="glm")
# Preprocess using PCA
preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
# Create Training Set from Preprocessed
train_PCA <- predict(preProcessed_PCA, new_training[, -13])
# Create the model from the created training set
modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
####################################################################################
## Model 2 - PCA, 80%, method = 'glm'
# # Preprocess using PCA
# preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
#
# # Create Training Set from Preprocessed
# train_PCA <- predict(preProcessed_PCA, new_training[, -13])
#
# # Create the model from the created training set
# modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
modelFit2 <- train(diagnosis ~., data = new_trainingL, method = "glm", preProcess = "pca",trControl=trainControl(preProcOptions=list(thresh=0.8)))
## Model 2 - PCA, 80%, method = 'glm'
# # Preprocess using PCA
# preProcessed_PCA <- preProcess(new_training[, -13], method = "pca", thresh = 0.8)
#
# # Create Training Set from Preprocessed
# train_PCA <- predict(preProcessed_PCA, new_training[, -13])
#
# # Create the model from the created training set
# modelFit2 <- train(new_training$diagnosis ~ ., data = train_PCA, method="glm")
modelFit2 <- train(diagnosis ~., data = new_training, method = "glm", preProcess = "pca",trControl=trainControl(preProcOptions=list(thresh=0.8)))
# #Create testsing set from preprocessed
# test_PCA <- predict(preProcessed_PCA, new_testing[, -13])
#
# predict(modelPCA, testingIL)
# Predict using model 2
predicted2 <- predict(modFit2, new_testing)
modelFit2 <- train(diagnosis ~., data = new_training, method = "glm", preProcess = "pca",trControl=trainControl(preProcOptions=list(thresh=0.8)))
# #Create testsing set from preprocessed
# test_PCA <- predict(preProcessed_PCA, new_testing[, -13])
#
# predict(modelPCA, testingIL)
# Predict using model 2
predicted2 <- predict(modelFit2, new_testing)
# create a Confusion Matrix
confusionMatrix(predicted2, testing$diagnosis)
sessionInfo()
install.packages("ElemStatLearn", dependencies = TRUE)
install.packages("pgmm", dependencies = TRUE)
install.packages("rpart", dependencies = TRUE)
install.packages("rpart", dependencies = TRUE)
install.packages("rpart", dependencies = TRUE)
install.packages("rpart", dependencies = TRUE)
install.packages("rpart", dependencies = TRUE)
library("rpart")
install.packages("rpart", dependencies = TRUE)
library("rpart")
segments()
segmentationOriginal
data(segmentationOriginal)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(ggplot2)
library(gridExtra)
library(Hmisc)
## Load the cell segmentation data from the AppliedPredictiveModeling package
data(segmentationOriginal)
segmentationOriginal
str(segmentationOriginal)
segmentationOriginal$Case
seg_Data
knitr::opts_chunk$set(echo = TRUE)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(ggplot2)
library(gridExtra)
library(Hmisc)
## Load the cell segmentation data from the AppliedPredictiveModeling package
seg_Data <- data(segmentationOriginal)
seg_Data
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(ggplot2)
library(gridExtra)
library(Hmisc)
## Load the cell segmentation data from the AppliedPredictiveModeling package
data(segmentationOriginal)
seg_Data <- segmentationOriginal
seg_Data
seg_Data[, grep("Test", seg_Data$Case)]
training <- seg_Data[which(seg_Data$Case == "Training")]
training$case
training <- seg_Data[which(seg_Data$Case == "Train")]
seg_Data$Case
which(seg_Data$Case == "Train")
seg_Data[which(seg_Data$Case == "Train")]$Case
seg_Data[which(seg_Data$Case == "Train")]
subset(seg_Data, Case == "Train")
training <- subset(seg_Data, Case == "Train")
training$Case
dim(training)
dim(testing)
#Subset and make training and testing sets
training <- subset(seg_Data, Case == "Train")
test <- subset(seg_Data, Case == "Test")
set.seed(125)
# Fit the CART Model using the rpart method
modFit <- train(Case ~ ., method="rpart", data=training)
training
#Subset and make training and testing sets
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7,
list = FALSE) # 70% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
# Fit the CART Model using the rpart method
modFit <- train(Case ~ ., method="rpart", data=training)
# Fit the CART Model using the rpart method
modFit <- train(Case ~ ., method="rpart", data=training)
# Prediction of different variable values
predict(modFit, newdata = subset(testing, TotalIntench2 = 23,000 & FiberWidthCh1 = 10 &  PerimStatusCh1=2))
#Subset and make training and testing sets
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7,
list = FALSE) # 70% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
# Fit the CART Model using the rpart method
modFit <- train(Case ~ ., method="rpart", data=training)
# Prediction of different variable values
predict(modFit, newdata == subset(testing, TotalIntench2 == 23,000 & FiberWidthCh1 == 10 &  PerimStatusCh1==2))
#Subset and make training and testing sets
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7,
list = FALSE) # 70% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
# Fit the CART Model using the rpart method
modFit <- train(Case ~ ., method="rpart", data=training)
# Prediction of different variable values
predict(modFit, newdata = subset(testing, TotalIntench2 == 23,000 & FiberWidthCh1 == 10 &  PerimStatusCh1==2))
subset(testing, TotalIntench2 == 23,000 & FiberWidthCh1 == 10 &  PerimStatusCh1==2))
subset(testing, TotalIntench2 == 23,000 & FiberWidthCh1 == 10 &  PerimStatusCh1==2)
subset(testing, PerimStatusCh1==2)
subset(testing, FiberWidthCh1 == 10)
subset(testing, TotalIntench2 == 23,000)
#Subset and make training and testing sets
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7,
list = FALSE) # 70% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
# Fit the CART Model using the rpart method
modFit <- train(Case ~ ., method="rpart", data=training)
# Prediction of different variable values
predict(modFit, newdata = subset(testing, TotalIntenCh2 == 23,000 & FiberWidthCh1 == 10 &  PerimStatusCh1==2))
subset(testing, TotalIntenCh2 == 23,000 & FiberWidthCh1 == 10 &  PerimStatusCh1==2)
predict(modFit, newdata = subset(testing, TotalIntenCh2 == 23,0002))
#Subset and make training and testing sets
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7,
list = FALSE) # 70% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
# Fit the CART Model using the rpart method
modFit <- train(Case ~ ., method="rpart", data=training)
# Final Model
modFit$finalModel
testing$Case
testing$Class
#Subset and make training and testing sets
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7,
list = FALSE) # 70% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
# Fit the CART Model using the rpart method
modFit <- train(class ~ ., method="rpart", data=training)
predict(modFit, newdata = subset(testing, TotalIntenCh2 == 23,0002))
subset(testing, TotalIntenCh2 == 23,0002))
install.packages("rattle", dependencies = TRUE)
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",na.strings=c("NA","#DIV/0!","") ) # Training Data
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings=c("NA","#DIV/0!","")) # Test Data
training$classe
str(training)
str(training$classe)
library("rattle", lib.loc="D:/R/R-3.4.1/library")
modFit <- train(classe~., data = newTraining, method = "rpart")
library(caret)
## Build the Decision Tree Model
modFitDT <- train(classe~., data = newTraining, method = "rpart")
install.packages("randomForest")
modFitBT <- traIn(classe ~., method = "gbm", data = newTraining)
View(new_training)
View(new_training)
library(caret)
library(Amelia)
library(pgmm)
library(rpart)
library(rpart.plot)
library(gbm)
library(lubridate)
library(randomForest)
library(e1071)
library(rattle)
#setting the seed for reproducible computation
set.seed(12345)
#setting the seed for reproducible computation
set.seed(12345)
## Read the Data
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",na.strings=c("NA","#DIV/0!","") ) # Training Data
x <- c(452500000, 472500000, 472500000)
)
x <- c(452500000, 472500000, 472500000)
x
hist(x)
y <- c("Year 1", "Year2", "Year3")
y
xy <- cbind(x, y)
xy
ggplot(data = xy, aes(x, y))
as.data.frame(xy)
xyNew <- as.data.frame(xy)
xyNew
str(xyNew)
ggplot(data = xy, aes(x, y))
ggplot(data = xyNew, aes(x, y))
ggplot(data = xyNew, aes(y, xy))
ggplot(data = xyNew, aes(y, x))
unlink('P:/NITA/New/Personal/Training/Data Science/John Hopkins/Course  8 - Machine Learning/Week 4/Course Project/Machine_Learning_Markdown-New_cache', recursive = TRUE)
install.packages(c("arules", "backports", "boot", "checkmate", "chron", "curl", "data.table", "ddalpha", "dplyr", "lava", "Matrix", "mgcv", "Rcpp", "RcppArmadillo", "tidyselect"))
install.packages(c("arules", "backports", "boot", "checkmate", "chron", "curl", "data.table", "ddalpha", "dplyr", "lava", "Matrix", "mgcv", "Rcpp", "RcppArmadillo", "tidyselect"))
install.packages(c("arules", "backports", "boot", "checkmate", "chron", "curl", "data.table", "ddalpha", "dplyr", "lava", "Matrix", "mgcv", "Rcpp", "RcppArmadillo", "tidyselect"))
training
```{r, warning=FALSE, tidy=TRUE, error=FALSE, results='hide'}
aa <- c("B", "c", "A", "E")
aa <- c("B", "c", "A", "E")
knitr::kable(
aa,
caption = "Predicted Cases."
)
as.data.frame(aa)
library(shiny)
library(miniUI)
myFirstGadget <-function() {
ui <- miniPage(
gadgetTitleBar("My First Gadget")
)
server <-function(input, output, session) {
# The Done button closes the app
observeEvent(input$done, {
stopApp()
})
}
runGadget(ui, server)
}
myFirstGadget()
source('P:/NITA/New/Personal/Training/Data Science/John Hopkins/Course 9 - Developing Data Products/Week 1/Application/shinyGadgetApp1.R')
myFirstGadget()
multiplyNumbers <-function(numbers1, numbers2) {
ui <- miniPage(
gadgetTitleBar("Multiply Two Numbers"),
miniContentPanel(
)
)
selectInput("num1","First Number",choices=numbers1),
selectInput("num2","Second Number",choices=numbers2)
)
)
server <-function(input, output, session) {
observeEvent(input$done, {
num1 <- as.numeric(input$num1)
num2 <- as.numeric(input$num2)
stopApp(num1 *num2)
})
}
runGadget(ui, server)
}
multiplyNumbers <-function(numbers1, numbers2) {
ui <- miniPage(
gadgetTitleBar("Multiply Two Numbers"),
miniContentPanel(
)
)
selectInput("num1","First Number",choices=numbers1),
selectInput("num2","Second Number",choices=numbers2)
}
)
server <-function(input, output, session) {
observeEvent(input$done, {
num1 <- as.numeric(input$num1)
num2 <- as.numeric(input$num2)
stopApp(num1 *num2)
})
}
runGadget(ui, server)
}
multiplyNumbers <-function(numbers1, numbers2) {
ui <- miniPage(
gadgetTitleBar("Multiply Two Numbers"),
miniContentPanel(
selectInput("num1","First Number",choices=numbers1),
selectInput("num2","Second Number",choices=numbers2)
)
)
server <-function(input, output, session) {
observeEvent(input$done, {
num1 <- as.numeric(input$num1)
num2 <- as.numeric(input$num2)
stopApp(num1 *num2)
})
}
runGadget(ui, server)
}
multiplyNumbers()
multiplyNumbers(1:10, 1:10)
pickTrees <-function() {
ui <- miniPage(
gadgetTitleBar("Select Points by Dragging your Mouse"),
miniContentPanel(
plotOutput("plot",height ="100%",brush ="brush")
)
)
server <-function(input, output, session) {
output$plot <- renderPlot({
plot(trees$Girth, trees$Volume,main ="Trees!",
xlab ="Girth",ylab ="Volume")
})
observeEvent(input$done, {
})
}
stopApp(brushedPoints(trees, input$brush,
xvar ="Girth",yvar ="Volume"))
runGadget(ui, server)
}
pickTrees()
shiny::runApp('P:/NITA/New/Personal/Training/Data Science/John Hopkins/Course 9 - Developing Data Products/Week 4/Peer-Graded/ITCertShinnyApp')
runApp('P:/NITA/New/Personal/Training/Data Science/John Hopkins/Course 9 - Developing Data Products/Week 4/Peer-Graded/ITCertShinnyApp')
shiny::runApp('P:/NITA/New/Personal/Training/Data Science/John Hopkins/Course 9 - Developing Data Products/Week 4/Peer-Graded/ITCertShinnyApp')
